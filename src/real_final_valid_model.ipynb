{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d874f98",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f09f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ====== 데이터 로드 ======\n",
    "train_candidates = [\n",
    "    Path(\"../data/29757_train_merged.csv\"),\n",
    "    Path(\"../data/1000_train_merged.csv\"),\n",
    "    Path(\"../data/10000_train_merged.csv\"),\n",
    "]\n",
    "test_candidates = [\n",
    "    Path(\"../data/29757_test_merged.csv\"),\n",
    "    Path(\"../data/1000_test_merged.csv\"),\n",
    "    Path(\"../data/10000_test_merged.csv\"),\n",
    "]\n",
    "\n",
    "def resolve_path(candidates: list[Path]) -> Path:\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No dataset found in: {candidates}\")\n",
    "\n",
    "train_df = pd.read_csv(resolve_path(train_candidates))\n",
    "test_df = pd.read_csv(resolve_path(test_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fadb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_col = \"died_in_icu\"\n",
    "\n",
    "datasets = {\n",
    "    \"train_proc\": train_df,\n",
    "    \"test_proc\": test_df,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "for ax, (name, df) in zip(axes, datasets.items()):\n",
    "    counts = df[target_col].value_counts().sort_index()\n",
    "    ratios = counts / counts.sum()\n",
    "\n",
    "    ax.bar(ratios.index.astype(str), ratios.values, color=[\"tab:blue\", \"tab:red\"])\n",
    "    ax.set_xlabel(target_col)\n",
    "    ax.set_title(f\"Class Ratio in {name}\")\n",
    "\n",
    "    for i, v in enumerate(ratios.values):\n",
    "        ax.text(i, v + 0.01, f\"{v:.2%}\", ha=\"center\")\n",
    "\n",
    "axes[0].set_ylabel(\"Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a1352",
   "metadata": {},
   "source": [
    "## 전처리 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 기본 설정 ======\n",
    "target_col = \"died_in_icu\"\n",
    "possible_group_cols = [\"patientunitstayid\", \"patient_id\"]\n",
    "possible_time_cols = [\"observationoffset\"]\n",
    "\n",
    "group_col = next((c for c in possible_group_cols if c in train_df.columns), None)\n",
    "time_col = next((c for c in possible_time_cols if c in train_df.columns), None)\n",
    "if group_col is None or time_col is None:\n",
    "    raise ValueError(\"patient id or time column not found\")\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "exclude = {target_col, \"patient_id\", \"patientunitstayid\", \"observationoffset\"}\n",
    "base_cols = [c for c in numeric_cols if c not in exclude]\n",
    "\n",
    "# ====== 함수 ======\n",
    "def add_missing_and_time_features(df: pd.DataFrame, base_cols: list[str]) -> pd.DataFrame:\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    for col in base_cols:\n",
    "        miss = df[col].isna().astype(int)\n",
    "        last_time = df[time_col].where(df[col].notna()).groupby(df[group_col]).ffill()\n",
    "        tsince = df[time_col] - last_time\n",
    "        tsince = tsince.fillna(df[time_col])\n",
    "        #df[f\"{col}_miss\"] = miss\n",
    "        #df[f\"{col}_tsince\"] = tsince\n",
    "    return df\n",
    "\n",
    "def impute_base(df: pd.DataFrame, base_cols: list[str], medians: pd.Series) -> pd.DataFrame:\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    df[base_cols] = df.groupby(group_col, sort=False)[base_cols].ffill()\n",
    "    df[base_cols] = df[base_cols].fillna(medians)\n",
    "    return df\n",
    "\n",
    "def sample_k_per_stay(df, group_col, time_col, k=10):\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    def pick_rows(g):\n",
    "        n = len(g)\n",
    "        if n <= k:\n",
    "            return g\n",
    "        idx = np.linspace(0, n - 1, k, dtype=int)\n",
    "        return g.iloc[idx]\n",
    "    return df.groupby(group_col, group_keys=False).apply(pick_rows)\n",
    "\n",
    "def balance_ratio(df, target_col=\"died_in_icu\", ratio_pos=0.08, random_state=42):\n",
    "    pos = df[df[target_col] == 1]\n",
    "    neg = df[df[target_col] == 0]\n",
    "    desired_neg = int(len(pos) * (1 - ratio_pos) / ratio_pos)\n",
    "\n",
    "    if desired_neg >= len(neg):\n",
    "        desired_pos = int(len(neg) * ratio_pos / (1 - ratio_pos))\n",
    "        pos = pos.sample(n=desired_pos, random_state=random_state)\n",
    "    else:\n",
    "        neg = neg.sample(n=desired_neg, random_state=random_state)\n",
    "\n",
    "    return pd.concat([pos, neg]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "def sample_total_rows_by_group(df, group_col, n_total=1000, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    groups = {gid: g.index.to_numpy() for gid, g in df.groupby(group_col)}\n",
    "    group_ids = list(groups.keys())\n",
    "    rng.shuffle(group_ids)\n",
    "    for gid in group_ids:\n",
    "        rng.shuffle(groups[gid])\n",
    "\n",
    "    picks = []\n",
    "    while len(picks) < n_total and group_ids:\n",
    "        next_group_ids = []\n",
    "        for gid in group_ids:\n",
    "            if len(picks) >= n_total:\n",
    "                break\n",
    "            idxs = groups[gid]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            picks.append(idxs[0])\n",
    "            groups[gid] = idxs[1:]\n",
    "            if len(groups[gid]) > 0:\n",
    "                next_group_ids.append(gid)\n",
    "        group_ids = next_group_ids\n",
    "\n",
    "    result = df.loc[picks].sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55657410",
   "metadata": {},
   "source": [
    "## 최종 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 사용 피처 ======\n",
    "\n",
    "feature_cols = base_cols #파생변수 + ID + 타겟 + 시간변수 제외\n",
    "\n",
    "\n",
    "\n",
    "# ====== 파이프라인: group 기준 랜덤 1000개 샘플  ======\n",
    "train_proc = sample_total_rows_by_group(train_df, group_col, n_total=1000, random_state=42)\n",
    "test_proc = sample_total_rows_by_group(test_df, group_col, n_total=1000, random_state=42)\n",
    "\n",
    "# ====== 파이프라인: stayid별 10개 샘플  ======\n",
    "train_proc = sample_k_per_stay(train_df, group_col, time_col, k=10)\n",
    "test_proc = sample_k_per_stay(test_df, group_col, time_col, k=10)\n",
    "\n",
    "# ====== 파생변수 생성 & 추가======\n",
    "# train_proc = add_missing_and_time_features(train_proc, base_cols)\n",
    "# test_proc = add_missing_and_time_features(test_proc, base_cols)\n",
    "\n",
    "# ====== 결측치 처리 ======\n",
    "\n",
    "train_medians = train_proc[base_cols].median()\n",
    "train_proc = impute_base(train_proc, base_cols, train_medians)\n",
    "test_proc = impute_base(test_proc, base_cols, train_medians)\n",
    "\n",
    "# ====== 클래스 비율 맞추기 (train만) ======\n",
    "train_proc = balance_ratio(train_proc, target_col=target_col, ratio_pos=0.08)\n",
    "test_proc = balance_ratio(test_proc, target_col=target_col, ratio_pos=0.08)\n",
    "\n",
    "# ====== 데이터셋 구성 ======\n",
    "X_train = train_proc[feature_cols]\n",
    "y_train = train_proc[target_col]\n",
    "\n",
    "X_test = test_proc[feature_cols]\n",
    "y_test = test_proc[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae1ae7",
   "metadata": {},
   "source": [
    "## 불균형 전처리 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_col = \"died_in_icu\"\n",
    "\n",
    "datasets = {\n",
    "    \"train_proc\": train_proc,\n",
    "    \"test_proc\": test_proc,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "for ax, (name, df) in zip(axes, datasets.items()):\n",
    "    counts = df[target_col].value_counts().sort_index()\n",
    "    ratios = counts / counts.sum()\n",
    "\n",
    "    ax.bar(ratios.index.astype(str), ratios.values, color=[\"tab:blue\", \"tab:red\"])\n",
    "    ax.set_xlabel(target_col)\n",
    "    ax.set_title(f\"Class Ratio in {name}\")\n",
    "\n",
    "    for i, v in enumerate(ratios.values):\n",
    "        ax.text(i, v + 0.01, f\"{v:.2%}\", ha=\"center\")\n",
    "\n",
    "axes[0].set_ylabel(\"Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887f2bf9",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db834385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 클래스 불균형 비율 계산\n",
    "\n",
    "scale_pos_weight = 92/8\n",
    "\n",
    "models = {\n",
    "    \"LR\": Pipeline([\n",
    "      #  (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=1000)),\n",
    "    ]),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    models[\"XGBoost\"] = xgb.XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# LightGBM\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    models[\"LightGBM\"] = lgb.LGBMClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "def aggregate_patient_scores(df: pd.DataFrame, scores: np.ndarray):\n",
    "    tmp = df[[group_col, target_col]].copy()\n",
    "    tmp[\"score\"] = scores\n",
    "    y_patient = tmp.groupby(group_col)[target_col].max()\n",
    "    s_patient = tmp.groupby(group_col)[\"score\"].mean()\n",
    "    return y_patient, s_patient\n",
    "\n",
    "pred_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        scores = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        raw = model.decision_function(X_test)\n",
    "        scores = 1 / (1 + np.exp(-raw))\n",
    "\n",
    "    pred_scores[name] = scores\n",
    "\n",
    "print(\"models used:\", list(pred_scores.keys()))\n",
    "print(\"test n:\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf80b11",
   "metadata": {},
   "source": [
    "## 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화: ROC + Calibration + Decision Curve (row-level)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1) ROC\n",
    "ax = axes[0]\n",
    "for name, scores in pred_scores.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "    auc = roc_auc_score(y_test, scores)\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "ax.set_xlabel(\"1 - Specificity\")\n",
    "ax.set_ylabel(\"Sensitivity\")\n",
    "ax.set_title(\"ROC Curves (row-level)\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# 2) Calibration\n",
    "ax = axes[1]\n",
    "for name, scores in pred_scores.items():\n",
    "    prob_true, prob_pred = calibration_curve(y_test, scores, n_bins=10, strategy=\"uniform\")\n",
    "    ax.plot(prob_pred, prob_true, marker=\"o\", label=name)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", alpha=0.5, label=\"Ideal\")\n",
    "ax.set_xlabel(\"Mean predicted probability\")\n",
    "ax.set_ylabel(\"Fraction of positives\")\n",
    "ax.set_title(\"Calibration Curves (row-level)\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# 3) Decision Curve\n",
    "ax = axes[2]\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "def decision_curve(y_true, scores):\n",
    "    n = len(y_true)\n",
    "    net_benefit = []\n",
    "    for t in thresholds:\n",
    "        preds = scores >= t\n",
    "        tp = ((preds == 1) & (y_true == 1)).sum()\n",
    "        fp = ((preds == 1) & (y_true == 0)).sum()\n",
    "        nb = (tp / n) - (fp / n) * (t / (1 - t))\n",
    "        net_benefit.append(nb)\n",
    "    return np.array(net_benefit)\n",
    "\n",
    "for name, scores in pred_scores.items():\n",
    "    nb = decision_curve(np.array(y_test), scores)\n",
    "    ax.plot(thresholds, nb, label=name)\n",
    "\n",
    "prevalence = np.mean(y_test)\n",
    "nb_all = prevalence - (1 - prevalence) * (thresholds / (1 - thresholds))\n",
    "ax.plot(thresholds, nb_all, \"k--\", alpha=0.4, label=\"Treat all\")\n",
    "ax.plot(thresholds, np.zeros_like(thresholds), \"k:\", alpha=0.6, label=\"Treat none\")\n",
    "\n",
    "ax.set_xlabel(\"Threshold probability\")\n",
    "ax.set_ylabel(\"Net benefit\")\n",
    "ax.set_title(\"Decision Curve Analysis (row-level)\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16395b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 서브플롯 (환자 단위 집계 기준)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "n_models = len(pred_scores)\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(n_models / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for ax, (name, scores) in zip(axes, pred_scores.items()):\n",
    "    y_pred = (scores >= 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
    "    ax.set_title(f\"{name}\")\n",
    "\n",
    "for ax in axes[n_models:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "\n",
    "def evaluate_row_level(\n",
    "    pred_scores: dict[str, np.ndarray | pd.Series],\n",
    "    y_true: np.ndarray | pd.Series,\n",
    "    threshold: float = 0.5,\n",
    ") -> pd.DataFrame:\n",
    "   \n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    results = []\n",
    "    for name, scores in pred_scores.items():\n",
    "        y_score = np.asarray(scores).astype(float)\n",
    "        y_pred = (y_score >= threshold).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        if np.unique(y_true).size < 2:\n",
    "            auc = np.nan\n",
    "            ap = np.nan\n",
    "        else:\n",
    "            auc = roc_auc_score(y_true, y_score)\n",
    "            ap = average_precision_score(y_true, y_score)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"N_rows\": len(y_true),\n",
    "            \"pos_rate\": float(y_true.mean()),\n",
    "            \"threshold\": threshold,\n",
    "            \"ACC\": acc,\n",
    "            \"PREC\": prec,\n",
    "            \"REC\": rec,\n",
    "            \"F1\": f1,\n",
    "            \"AUC\": auc,\n",
    "            \"PR-AUC\": ap,\n",
    "        })\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame(results)\n",
    "        .set_index(\"model\")\n",
    "        .sort_values([\"PR-AUC\", \"AUC\"], ascending=False)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "metrics_df = evaluate_row_level(\n",
    "    pred_scores=pred_scores,\n",
    "    y_true=y_test,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "print(metrics_df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e30b2",
   "metadata": {},
   "source": [
    "## SHAP 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6714519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 분석 + 중요 피처 Top-N (row-level, 현재 models 기준)\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_shap = X_test.sample(n=min(1000, len(X_test)), random_state=42)\n",
    "top_n = 30\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        if name in [\"RF\", \"XGBoost\", \"LightGBM\"]:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_shap)\n",
    "        else:\n",
    "            bg = X_shap.sample(100, random_state=42)\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, bg)\n",
    "            shap_values = explainer.shap_values(X_shap, nsamples=100)\n",
    "\n",
    "        if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "            sv = shap_values[1]\n",
    "        else:\n",
    "            sv = shap_values\n",
    "\n",
    "        mean_abs = np.abs(sv).mean(axis=0)\n",
    "        imp = pd.Series(mean_abs, index=X_shap.columns).sort_values(ascending=False)\n",
    "\n",
    "        print(f\"\\n{name} Top {top_n} features:\")\n",
    "        print(imp.head(top_n))\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        imp.head(top_n).sort_values().plot(kind=\"barh\")\n",
    "        plt.title(f\"{name} SHAP Feature Importance (Top {top_n})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shap.summary_plot(sv, X_shap, show=True, plot_type=\"bar\")\n",
    "        shap.summary_plot(sv, X_shap, show=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP failed for {name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

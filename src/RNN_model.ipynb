{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29fc04b7",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9406ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_model import TSB_MIMIC_IV  # uses diff_models.diff_CSDI internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed41654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "n_features(K): 37\n",
      "rows train/valid: (3903369, 40) (965199, 40)\n",
      "n_stays train/valid/test: 23595 5898 7355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ijaeyong/Desktop/Oracle_BC/mini_project/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 311\u001b[39m\n\u001b[32m    308\u001b[39m cond_mask = csdi.get_randmask(obs_mask)\n\u001b[32m    309\u001b[39m side_info = csdi.get_side_info(cond_mask)\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m loss = \u001b[43mcsdi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcalc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m opt.zero_grad()\n\u001b[32m    313\u001b[39m loss.backward()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 239\u001b[39m, in \u001b[36mcalc_loss_fixed\u001b[39m\u001b[34m(self, observed_data, cond_mask, observed_mask, side_info, is_train, seq_length, set_t)\u001b[39m\n\u001b[32m    236\u001b[39m noisy_data = (current_alpha ** \u001b[32m0.5\u001b[39m) * observed_data + ((\u001b[32m1.0\u001b[39m - current_alpha) ** \u001b[32m0.5\u001b[39m) * noise\n\u001b[32m    238\u001b[39m total_input = \u001b[38;5;28mself\u001b[39m.set_input_to_diffmodel(noisy_data, observed_data, cond_mask)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m predicted = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiffmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m target_mask = observed_mask - cond_mask\n\u001b[32m    242\u001b[39m residual = (noise - predicted) * target_mask\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oracle_BC/mini_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oracle_BC/mini_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oracle_BC/mini_project/src/diff_models.py:66\u001b[39m, in \u001b[36mdiff_CSDI.forward\u001b[39m\u001b[34m(self, x, cond_info, diffusion_step, seq_length)\u001b[39m\n\u001b[32m     63\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.input_projection(x))\n\u001b[32m     64\u001b[39m x = x.view(B, \u001b[38;5;28mself\u001b[39m.channels, K, L)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m diffusion_emb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdiffusion_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m skip_connections = []\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.residual_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oracle_BC/mini_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oracle_BC/mini_project/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Oracle_BC/mini_project/src/diff_models.py:26\u001b[39m, in \u001b[36mDiffusionEmbedding.forward\u001b[39m\u001b[34m(self, diffusion_step)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, diffusion_step):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdiffusion_step\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m     x = F.silu(\u001b[38;5;28mself\u001b[39m.projection1(x))\n\u001b[32m     28\u001b[39m     x = F.silu(\u001b[38;5;28mself\u001b[39m.projection2(x))\n",
      "\u001b[31mRuntimeError\u001b[39m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CSDI diffusion(imputation) + GRU mortality prediction (M1 Air friendly)\n",
    "# - uses your diff_models.py (diff_CSDI) and main_model.py (TSB_eICU)\n",
    "# - NO external ffill/median imputation. We only build observed_mask and fill NaN->0 inside observed_data.\n",
    "# - VALID threshold tuning, TEST fixed threshold\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 0) seed / device (M1: mps)\n",
    "# ----------------------------\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) import your modules\n",
    "# ----------------------------\n",
    "# (필요하면) 현재 경로를 PYTHONPATH에 추가\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) load data\n",
    "# ----------------------------\n",
    "train_candidates = [\n",
    "    Path(\"../data/29757_train_merged.csv\"),\n",
    "    Path(\"../data/1000_train_merged.csv\"),\n",
    "    Path(\"../data/10000_train_merged.csv\"),\n",
    "]\n",
    "test_candidates = [\n",
    "    Path(\"../data/29757_test_merged.csv\"),\n",
    "    Path(\"../data/1000_test_merged.csv\"),\n",
    "    Path(\"../data/10000_test_merged.csv\"),\n",
    "]\n",
    "\n",
    "def resolve_path(candidates: list[Path]) -> Path:\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No dataset found in: {candidates}\")\n",
    "\n",
    "train_path = resolve_path(train_candidates)\n",
    "test_path = resolve_path(test_candidates)\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "target_col = \"died_in_icu\"\n",
    "possible_group_cols = [\"patientunitstayid\", \"patient_id\"]\n",
    "possible_time_cols = [\"observationoffset\"]\n",
    "\n",
    "group_col = next((c for c in possible_group_cols if c in train_df.columns), None)\n",
    "time_col = next((c for c in possible_time_cols if c in train_df.columns), None)\n",
    "if group_col is None or time_col is None:\n",
    "    raise ValueError(\"group/time column not found\")\n",
    "\n",
    "# patient_id leakage guard (if exists)\n",
    "if \"patient_id\" in train_df.columns and \"patient_id\" in test_df.columns:\n",
    "    overlap = set(train_df[\"patient_id\"].unique()) & set(test_df[\"patient_id\"].unique())\n",
    "    assert len(overlap) == 0, f\"patient_id leakage! overlap={len(overlap)}\"\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "exclude = {target_col, \"patient_id\", \"patientunitstayid\"}\n",
    "feature_cols = [c for c in numeric_cols if c not in exclude]\n",
    "K = len(feature_cols)\n",
    "print(\"n_features(K):\", K)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) group-stratified train/valid split (by stay)\n",
    "# ----------------------------\n",
    "def group_stratified_split(df: pd.DataFrame, group_col: str, target_col: str, valid_ratio=0.2, seed=42):\n",
    "    stay_y = df.groupby(group_col)[target_col].max()\n",
    "    pos = stay_y[stay_y == 1].index.to_list()\n",
    "    neg = stay_y[stay_y == 0].index.to_list()\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rng.shuffle(pos)\n",
    "    rng.shuffle(neg)\n",
    "\n",
    "    n_pos_val = int(len(pos) * valid_ratio)\n",
    "    n_neg_val = int(len(neg) * valid_ratio)\n",
    "\n",
    "    val_groups = set(pos[:n_pos_val] + neg[:n_neg_val])\n",
    "    tr_groups = set(stay_y.index) - val_groups\n",
    "\n",
    "    tr = df[df[group_col].isin(tr_groups)].copy()\n",
    "    va = df[df[group_col].isin(val_groups)].copy()\n",
    "    return tr, va\n",
    "\n",
    "train_part, valid_part = group_stratified_split(train_df, group_col, target_col, valid_ratio=0.2, seed=42)\n",
    "print(\"rows train/valid:\", train_part.shape, valid_part.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) build sequences -> batch dict for TSB_eICU.process_data()\n",
    "#    observed_data: (B, L, K) with NaN replaced by 0\n",
    "#    observed_mask: (B, L, K) 1 if observed else 0\n",
    "#    gt_mask: here set to observed_mask (we'll create cond_mask separately during training)\n",
    "#    offsets: (B, L) padded time values (not used by model core, but required key)\n",
    "#    seq_length: (B,)\n",
    "# ----------------------------\n",
    "MAX_SEQ_LEN = 128  # M1 friendly\n",
    "TAKE = \"last\"      # use latest part\n",
    "\n",
    "def build_stay_arrays(df: pd.DataFrame, group_col: str, time_col: str, feature_cols: list[str], target_col: str,\n",
    "                      max_seq_len=128, take=\"last\"):\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    stays = []\n",
    "\n",
    "    for sid, g in df.groupby(group_col, sort=False):\n",
    "        t = g[time_col].to_numpy(dtype=np.float32)\n",
    "        x = g[feature_cols].to_numpy(dtype=np.float32)  # may contain NaN\n",
    "\n",
    "        if len(g) > max_seq_len:\n",
    "            if take == \"last\":\n",
    "                t = t[-max_seq_len:]\n",
    "                x = x[-max_seq_len:]\n",
    "            else:\n",
    "                t = t[:max_seq_len]\n",
    "                x = x[:max_seq_len]\n",
    "\n",
    "        m = (~np.isnan(x)).astype(np.float32)      # observed mask\n",
    "        x0 = np.nan_to_num(x, nan=0.0).astype(np.float32)  # NaN -> 0 in observed_data\n",
    "\n",
    "        y = int(g[target_col].max())\n",
    "        stays.append((sid, x0, m, t, y, len(t)))\n",
    "\n",
    "    return stays\n",
    "\n",
    "train_stays = build_stay_arrays(train_part, group_col, time_col, feature_cols, target_col, MAX_SEQ_LEN, TAKE)\n",
    "valid_stays = build_stay_arrays(valid_part, group_col, time_col, feature_cols, target_col, MAX_SEQ_LEN, TAKE)\n",
    "test_stays  = build_stay_arrays(test_df,     group_col, time_col, feature_cols, target_col, MAX_SEQ_LEN, TAKE)\n",
    "\n",
    "print(\"n_stays train/valid/test:\", len(train_stays), len(valid_stays), len(test_stays))\n",
    "\n",
    "class StayDataset(Dataset):\n",
    "    def __init__(self, stays):\n",
    "        self.stays = stays\n",
    "    def __len__(self):\n",
    "        return len(self.stays)\n",
    "    def __getitem__(self, idx):\n",
    "        sid, x0, m, t, y, L = self.stays[idx]\n",
    "        return sid, x0, m, t, y, L\n",
    "\n",
    "def collate_stays(batch):\n",
    "    # batch: list of (sid, x0[L,K], m[L,K], t[L], y, L)\n",
    "    B = len(batch)\n",
    "    Lmax = max(b[5] for b in batch)\n",
    "    K = batch[0][1].shape[1]\n",
    "\n",
    "    patient_id = np.zeros((B,), dtype=np.int64)\n",
    "    observed_data = np.zeros((B, Lmax, K), dtype=np.float32)\n",
    "    observed_mask = np.zeros((B, Lmax, K), dtype=np.float32)\n",
    "    gt_mask = np.zeros((B, Lmax, K), dtype=np.float32)\n",
    "    offsets = np.zeros((B, Lmax), dtype=np.float32)\n",
    "    status = np.zeros((B,), dtype=np.int64)\n",
    "    seq_length = np.zeros((B,), dtype=np.int64)\n",
    "\n",
    "    for i, (sid, x0, m, t, y, L) in enumerate(batch):\n",
    "        patient_id[i] = int(sid) if np.isscalar(sid) else i\n",
    "        observed_data[i, :L] = x0\n",
    "        observed_mask[i, :L] = m\n",
    "        gt_mask[i, :L] = m\n",
    "        offsets[i, :L] = t\n",
    "        status[i] = int(y)\n",
    "        seq_length[i] = int(L)\n",
    "\n",
    "    return {\n",
    "        \"patient_id\": torch.from_numpy(patient_id),\n",
    "        \"observed_data\": torch.from_numpy(observed_data),\n",
    "        \"observed_mask\": torch.from_numpy(observed_mask),\n",
    "        \"gt_mask\": torch.from_numpy(gt_mask),\n",
    "        \"status\": torch.from_numpy(status),\n",
    "        \"offsets\": torch.from_numpy(offsets),\n",
    "        \"seq_length\": torch.from_numpy(seq_length),\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# 5) diffusion model config (M1 friendly)\n",
    "# ----------------------------\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"featureemb\": 16,\n",
    "        \"target_strategy\": \"random\",  # use get_randmask\n",
    "    },\n",
    "    \"diffusion\": {\n",
    "        \"num_steps\": 20,                 # M1 friendly\n",
    "        \"schedule\": \"linear\",\n",
    "        \"beta_start\": 1e-4,\n",
    "        \"beta_end\": 2e-2,\n",
    "        \"channels\": 64,\n",
    "        \"diffusion_embedding_dim\": 64,\n",
    "        \"nheads\": 4,\n",
    "        \"layers\": 4,\n",
    "    }\n",
    "}\n",
    "\n",
    "csdi = TSB_MIMIC_IV(config=config, device=device, target_dim=K).to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) patch calc_loss bug (train uses randint, eval uses full)\n",
    "# ----------------------------\n",
    "def calc_loss_fixed(self, observed_data, cond_mask, observed_mask, side_info, is_train, seq_length, set_t=-1):\n",
    "    # observed_data: (B,K,L)\n",
    "    B, K, L = observed_data.shape\n",
    "    if is_train == 1:\n",
    "        t = torch.randint(0, self.num_steps, (B,), device=self.device, dtype=torch.long)\n",
    "    else:\n",
    "        t = torch.full((B,), int(set_t), device=self.device, dtype=torch.long)\n",
    "\n",
    "    current_alpha = self.alpha_torch[t]  # (B,1,1)\n",
    "    noise = torch.randn_like(observed_data)\n",
    "    noisy_data = (current_alpha ** 0.5) * observed_data + ((1.0 - current_alpha) ** 0.5) * noise\n",
    "\n",
    "    total_input = self.set_input_to_diffmodel(noisy_data, observed_data, cond_mask)\n",
    "    predicted = self.diffmodel(total_input, side_info, t, seq_length)\n",
    "\n",
    "    target_mask = observed_mask - cond_mask\n",
    "    residual = (noise - predicted) * target_mask\n",
    "    num_eval = target_mask.sum()\n",
    "    loss = (residual ** 2).sum() / (num_eval if num_eval > 0 else 1)\n",
    "    return loss\n",
    "\n",
    "import types\n",
    "csdi.calc_loss = types.MethodType(calc_loss_fixed, csdi)\n",
    "\n",
    "# ----------------------------\n",
    "# 7) train diffusion (imputation) model\n",
    "# ----------------------------\n",
    "batch_train = 8   # M1 friendly\n",
    "batch_eval = 16\n",
    "\n",
    "train_loader = DataLoader(StayDataset(train_stays), batch_size=batch_train, shuffle=True,\n",
    "                          num_workers=0, collate_fn=collate_stays, drop_last=False)\n",
    "valid_loader = DataLoader(StayDataset(valid_stays), batch_size=batch_eval, shuffle=False,\n",
    "                          num_workers=0, collate_fn=collate_stays, drop_last=False)\n",
    "test_loader  = DataLoader(StayDataset(test_stays),  batch_size=batch_eval, shuffle=False,\n",
    "                          num_workers=0, collate_fn=collate_stays, drop_last=False)\n",
    "\n",
    "opt = torch.optim.AdamW(csdi.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_diffusion_loss(model, loader, t_list=(0, 5, 10, 15)):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for batch in loader:\n",
    "        # to device\n",
    "        obs_data = batch[\"observed_data\"].to(device).float()   # (B,L,K)\n",
    "        obs_mask = batch[\"observed_mask\"].to(device).float()\n",
    "        seq_len  = batch[\"seq_length\"].to(device).long()\n",
    "\n",
    "        # (B,K,L)\n",
    "        obs_data = obs_data.permute(0, 2, 1)\n",
    "        obs_mask = obs_mask.permute(0, 2, 1)\n",
    "\n",
    "        # random cond_mask even in valid (to evaluate recovery objective consistently)\n",
    "        cond_mask = model.get_randmask(obs_mask)\n",
    "        side_info = model.get_side_info(cond_mask)\n",
    "\n",
    "        # average few fixed t's (cheap)\n",
    "        l = 0.0\n",
    "        for tt in t_list:\n",
    "            l = l + float(model.calc_loss(obs_data, cond_mask, obs_mask, side_info, is_train=0, seq_length=seq_len, set_t=tt).item())\n",
    "        losses.append(l / len(t_list))\n",
    "    return float(np.mean(losses)) if losses else float(\"nan\")\n",
    "\n",
    "EPOCHS_DIFF = 10       # M1 friendly\n",
    "PATIENCE = 2\n",
    "\n",
    "best_state = None\n",
    "best_vloss = float(\"inf\")\n",
    "pat = 0\n",
    "\n",
    "for ep in range(1, EPOCHS_DIFF + 1):\n",
    "    csdi.train()\n",
    "    tr_losses = []\n",
    "    for batch in train_loader:\n",
    "        obs_data = batch[\"observed_data\"].to(device).float()   # (B,L,K)\n",
    "        obs_mask = batch[\"observed_mask\"].to(device).float()\n",
    "        seq_len  = batch[\"seq_length\"].to(device).long()\n",
    "\n",
    "        obs_data = obs_data.permute(0, 2, 1)  # (B,K,L)\n",
    "        obs_mask = obs_mask.permute(0, 2, 1)\n",
    "\n",
    "        cond_mask = csdi.get_randmask(obs_mask)\n",
    "        side_info = csdi.get_side_info(cond_mask)\n",
    "\n",
    "        loss = csdi.calc_loss(obs_data, cond_mask, obs_mask, side_info, is_train=1, seq_length=seq_len)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(csdi.parameters(), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        tr_losses.append(loss.item())\n",
    "\n",
    "    vloss = valid_diffusion_loss(csdi, valid_loader)\n",
    "    print(f\"[DIFF {ep:02d}] train_loss={np.mean(tr_losses):.4f} valid_loss={vloss:.4f}\")\n",
    "\n",
    "    if vloss < best_vloss:\n",
    "        best_vloss = vloss\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in csdi.state_dict().items()}\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= PATIENCE:\n",
    "            print(\"Diffusion early stop.\")\n",
    "            break\n",
    "\n",
    "assert best_state is not None\n",
    "csdi.load_state_dict(best_state)\n",
    "csdi.to(device)\n",
    "csdi.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 8) GRU classifier on imputed sequences (generated by diffusion)\n",
    "# ----------------------------\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden=64):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: (B,L,K)\n",
    "        lengths_sorted, perm = lengths.sort(descending=True)\n",
    "        x_sorted = x[perm]\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(x_sorted, lengths_sorted.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        _, h = self.gru(packed)\n",
    "        h_last = h[-1]\n",
    "        _, inv = perm.sort()\n",
    "        h_last = h_last[inv]\n",
    "        return self.fc(h_last).squeeze(-1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def impute_batch_median(model, batch, n_samples=1):\n",
    "    # returns imputed_x: (B,L,K), y: (B,), lengths: (B,)\n",
    "    obs_data = batch[\"observed_data\"].to(device).float()   # (B,L,K)\n",
    "    obs_mask = batch[\"observed_mask\"].to(device).float()\n",
    "    y = batch[\"status\"].to(device).float()\n",
    "    lengths = batch[\"seq_length\"].to(device).long()\n",
    "\n",
    "    # (B,K,L)\n",
    "    obs_data_KL = obs_data.permute(0, 2, 1)\n",
    "    obs_mask_KL = obs_mask.permute(0, 2, 1)\n",
    "\n",
    "    # condition on all observed values\n",
    "    cond_mask = obs_mask_KL\n",
    "    side_info = model.get_side_info(cond_mask)\n",
    "\n",
    "    samples = model.impute(obs_data_KL, cond_mask, side_info, n_samples=n_samples, seq_length=lengths)  # (B,n,K,L)\n",
    "    # median across samples -> (B,K,L)\n",
    "    med = torch.median(samples, dim=1).values\n",
    "    # fill missing positions with generated, keep observed as original\n",
    "    imputed_KL = cond_mask * obs_data_KL + (1.0 - cond_mask) * med\n",
    "    imputed_LK = imputed_KL.permute(0, 2, 1).contiguous()  # (B,L,K)\n",
    "    return imputed_LK, y, lengths\n",
    "\n",
    "def tune_threshold_f1(y_true, probs, grid=401):\n",
    "    best_thr, best_f1 = 0.5, -1.0\n",
    "    for thr in np.linspace(0, 1, grid):\n",
    "        f1 = f1_score(y_true, (probs >= thr).astype(int), zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = float(thr)\n",
    "    return best_thr, best_f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_gru(csdi_model, gru_model, loader, n_samples=1):\n",
    "    csdi_model.eval()\n",
    "    gru_model.eval()\n",
    "    probs_all, y_all = [], []\n",
    "    for batch in loader:\n",
    "        x_imp, y, lengths = impute_batch_median(csdi_model, batch, n_samples=n_samples)\n",
    "        logits = gru_model(x_imp, lengths)\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        probs_all.append(probs)\n",
    "        y_all.append(y.detach().cpu().numpy())\n",
    "    return np.concatenate(probs_all), np.concatenate(y_all)\n",
    "\n",
    "def metrics(y_true, probs, thr):\n",
    "    y_pred = (probs >= thr).astype(int)\n",
    "    return {\n",
    "        \"AUC\": roc_auc_score(y_true, probs) if len(np.unique(y_true)) > 1 else np.nan,\n",
    "        \"AP\": average_precision_score(y_true, probs) if len(np.unique(y_true)) > 1 else np.nan,\n",
    "        \"P\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"R\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n",
    "\n",
    "gru = GRUClassifier(input_dim=K, hidden=64).to(device)\n",
    "gru_opt = torch.optim.AdamW(gru.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# pos_weight based on TRAIN stays labels\n",
    "y_train_stay = np.array([s[4] for s in train_stays], dtype=np.int64)\n",
    "pos = float(y_train_stay.sum())\n",
    "neg = float(len(y_train_stay) - y_train_stay.sum())\n",
    "pos_weight = torch.tensor([neg / max(pos, 1.0)], dtype=torch.float32).to(device)\n",
    "bce = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "EPOCHS_GRU = 12      # M1 friendly\n",
    "PATIENCE_GRU = 2\n",
    "N_SAMPLES_IMPUTE = 1 # M1 friendly (increase to 3 if you want, but slower)\n",
    "\n",
    "best_gru = None\n",
    "best_val_ap = -1.0\n",
    "pat = 0\n",
    "\n",
    "for ep in range(1, EPOCHS_GRU + 1):\n",
    "    gru.train()\n",
    "    losses = []\n",
    "    for batch in train_loader:\n",
    "        # on-the-fly imputation (diffusion frozen)\n",
    "        x_imp, y, lengths = impute_batch_median(csdi, batch, n_samples=N_SAMPLES_IMPUTE)\n",
    "\n",
    "        logits = gru(x_imp, lengths)\n",
    "        loss = bce(logits, y)\n",
    "\n",
    "        gru_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(gru.parameters(), 1.0)\n",
    "        gru_opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # VALID evaluate (threshold-free metric: AP)\n",
    "    va_probs, va_y = eval_gru(csdi, gru, valid_loader, n_samples=N_SAMPLES_IMPUTE)\n",
    "    va_ap = average_precision_score(va_y, va_probs) if len(np.unique(va_y)) > 1 else np.nan\n",
    "    va_auc = roc_auc_score(va_y, va_probs) if len(np.unique(va_y)) > 1 else np.nan\n",
    "    print(f\"[GRU {ep:02d}] train_loss={np.mean(losses):.4f} | VALID AUC={va_auc:.4f} AP={va_ap:.4f}\")\n",
    "\n",
    "    if va_ap > best_val_ap:\n",
    "        best_val_ap = va_ap\n",
    "        best_gru = {k: v.detach().cpu().clone() for k, v in gru.state_dict().items()}\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= PATIENCE_GRU:\n",
    "            print(\"GRU early stop.\")\n",
    "            break\n",
    "\n",
    "assert best_gru is not None\n",
    "gru.load_state_dict(best_gru)\n",
    "gru.to(device)\n",
    "gru.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 9) VALID threshold tuning -> TEST fixed\n",
    "# ----------------------------\n",
    "va_probs, va_y = eval_gru(csdi, gru, valid_loader, n_samples=N_SAMPLES_IMPUTE)\n",
    "thr, _ = tune_threshold_f1(va_y, va_probs, grid=401)\n",
    "print(\"\\n[VALID] tuned thr:\", thr)\n",
    "print(\"[VALID]\", metrics(va_y, va_probs, thr))\n",
    "\n",
    "te_probs, te_y = eval_gru(csdi, gru, test_loader, n_samples=N_SAMPLES_IMPUTE)\n",
    "print(\"\\n[TEST] thr(from VALID):\", thr)\n",
    "print(\"[TEST]\", metrics(te_y, te_probs, thr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f5657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

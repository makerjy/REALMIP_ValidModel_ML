{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377fd098",
   "metadata": {},
   "source": [
    "## 데이터 로드 및 기본 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8cb7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m커널을 시작하지 못했습니다. \n",
      "\u001b[1;31m커널이 종료되었습니다. 오류: ... 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ====== 데이터 로드 ======\n",
    "train_candidates = [\n",
    "    Path(\"../data/29757_train_merged.csv\"),\n",
    "    Path(\"../data/1000_train_merged.csv\"),\n",
    "    Path(\"../data/10000_train_merged.csv\"),\n",
    "]\n",
    "test_candidates = [\n",
    "    Path(\"../data/29757_test_merged.csv\"),\n",
    "    Path(\"../data/1000_test_merged.csv\"),\n",
    "    Path(\"../data/10000_test_merged.csv\"),\n",
    "]\n",
    "\n",
    "def resolve_path(candidates: list[Path]) -> Path:\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No dataset found in: {candidates}\")\n",
    "\n",
    "train_df = pd.read_csv(resolve_path(train_candidates))\n",
    "test_df = pd.read_csv(resolve_path(test_candidates))\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9cb3b",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd254168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 기본 설정 ======\n",
    "target_col = \"died_in_icu\"\n",
    "possible_group_cols = [\"patientunitstayid\", \"patient_id\"]\n",
    "possible_time_cols = [\"observationoffset\"]\n",
    "\n",
    "group_col = next((c for c in possible_group_cols if c in train_df.columns), None)\n",
    "time_col = next((c for c in possible_time_cols if c in train_df.columns), None)\n",
    "if group_col is None or time_col is None:\n",
    "    raise ValueError(\"patient id or time column not found\")\n",
    "\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "exclude = {target_col, \"patient_id\", \"patientunitstayid\", \"observationoffset\", \"feature35\", \"feature36\"}\n",
    "base_cols = [c for c in numeric_cols if c not in exclude]\n",
    "\n",
    "# ====== 함수 ======\n",
    "def add_missing_and_time_features(df: pd.DataFrame, base_cols: list[str]) -> pd.DataFrame:\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    for col in base_cols:\n",
    "        miss = df[col].isna().astype(int)\n",
    "        last_time = df[time_col].where(df[col].notna()).groupby(df[group_col]).ffill()\n",
    "        tsince = df[time_col] - last_time\n",
    "        tsince = tsince.fillna(df[time_col])\n",
    "        df[f\"{col}_miss\"] = miss\n",
    "        #df[f\"{col}_tsince\"] = tsince\n",
    "    return df\n",
    "\n",
    "def impute_base(df: pd.DataFrame, base_cols: list[str], medians: pd.Series) -> pd.DataFrame:\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    df[base_cols] = df.groupby(group_col, sort=False)[base_cols].ffill()\n",
    "    df[base_cols] = df[base_cols].fillna(medians)\n",
    "    return df\n",
    "\n",
    "def sample_k_per_stay(df, group_col, time_col, k=10):\n",
    "    df = df.sort_values([group_col, time_col]).copy()\n",
    "    def pick_rows(g):\n",
    "        n = len(g)\n",
    "        if n <= k:\n",
    "            return g\n",
    "        idx = np.linspace(0, n - 1, k, dtype=int)\n",
    "        return g.iloc[idx]\n",
    "    return df.groupby(group_col, group_keys=False).apply(pick_rows)\n",
    "\n",
    "def balance_ratio(df, target_col=\"died_in_icu\", ratio_pos=0.08, random_state=42):\n",
    "    pos = df[df[target_col] == 1]\n",
    "    neg = df[df[target_col] == 0]\n",
    "    desired_neg = int(len(pos) * (1 - ratio_pos) / ratio_pos)\n",
    "\n",
    "    if desired_neg >= len(neg):\n",
    "        desired_pos = int(len(neg) * ratio_pos / (1 - ratio_pos))\n",
    "        pos = pos.sample(n=desired_pos, random_state=random_state)\n",
    "    else:\n",
    "        neg = neg.sample(n=desired_neg, random_state=random_state)\n",
    "\n",
    "    return pd.concat([pos, neg]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "\n",
    "# ====== 나이 필터(옵션) ======\n",
    "def apply_age_filter(\n",
    "    train_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    age_col: str = \"age\",   # 실제 컬럼명으로 수정\n",
    "    min_age: int | None = None,\n",
    "    max_age: int | None = None,\n",
    "    enabled: bool = True,\n",
    "):\n",
    "    if not enabled or age_col not in train_df.columns or age_col not in test_df.columns:\n",
    "        return train_df, test_df\n",
    "    t = train_df\n",
    "    s = test_df\n",
    "    if min_age is not None:\n",
    "        t = t[t[age_col] >= min_age]\n",
    "        s = s[s[age_col] >= min_age]\n",
    "    if max_age is not None:\n",
    "        t = t[t[age_col] <= max_age]\n",
    "        s = s[s[age_col] <= max_age]\n",
    "    return t, s\n",
    "\n",
    "def sample_total_rows_by_group(df, group_col, n_total=1000, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    groups = {gid: g.index.to_numpy() for gid, g in df.groupby(group_col)}\n",
    "    group_ids = list(groups.keys())\n",
    "    rng.shuffle(group_ids)\n",
    "    for gid in group_ids:\n",
    "        rng.shuffle(groups[gid])\n",
    "\n",
    "    picks = []\n",
    "    while len(picks) < n_total and group_ids:\n",
    "        next_group_ids = []\n",
    "        for gid in group_ids:\n",
    "            if len(picks) >= n_total:\n",
    "                break\n",
    "            idxs = groups[gid]\n",
    "            if len(idxs) == 0:\n",
    "                continue\n",
    "            picks.append(idxs[0])\n",
    "            groups[gid] = idxs[1:]\n",
    "            if len(groups[gid]) > 0:\n",
    "                next_group_ids.append(gid)\n",
    "        group_ids = next_group_ids\n",
    "\n",
    "    result = df.loc[picks].sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74fe700",
   "metadata": {},
   "source": [
    "## 최종 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b0bd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# ====== 사용 피처 ======\n",
    "\n",
    "feature_cols = base_cols\n",
    "\n",
    "\n",
    "# ====== 나이 필터 적용 (옵션) ======\n",
    "train_df, test_df = apply_age_filter(train_df, test_df, age_col=\"feature1\", min_age=18, max_age=60, enabled=True)\n",
    "print(f\"Filtered Data shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "# ====== 파이프라인: group 기준 랜덤 1000개 샘플 → 결측치 처리 ======\n",
    "train_proc = sample_total_rows_by_group(train_df, group_col, n_total=1000, random_state=42)\n",
    "test_proc = sample_total_rows_by_group(test_df, group_col, n_total=1000, random_state=42)\n",
    "\n",
    "# ====== 파이프라인: stayid별 10개 샘플 → 결측치 처리 ======\n",
    "#train_proc = sample_k_per_stay(train_df, group_col, time_col, k=10)\n",
    "#test_proc = sample_k_per_stay(test_df, group_col, time_col, k=10)\n",
    "\n",
    "\n",
    "# ===== 파생변수 생성 & 추가======\n",
    "\n",
    "# train_proc = add_missing_and_time_features(train_proc, base_cols)\n",
    "# test_proc = add_missing_and_time_features(test_df, base_cols)\n",
    "\n",
    "# ===== 결측치 처리 =====\n",
    "train_medians = train_proc[base_cols].median()\n",
    "train_proc = impute_base(train_proc, base_cols, train_medians)\n",
    "test_proc = impute_base(test_proc, base_cols, train_medians)\n",
    "\n",
    "# ====== 클래스 비율 맞추기 (train만) ======\n",
    "train_proc = balance_ratio(train_proc, target_col=target_col, ratio_pos=0.08)\n",
    "#test_proc = balance_ratio(test_proc, target_col=target_col, ratio_pos=0.08)\n",
    "\n",
    "# ====== 데이터셋 구성 ======\n",
    "X_train = train_proc[feature_cols]\n",
    "y_train = train_proc[target_col] \n",
    "\n",
    "X_test = test_proc[feature_cols]\n",
    "y_test = test_proc[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_col = \"died_in_icu\"\n",
    "\n",
    "datasets = {\n",
    "    \"train_proc\": train_proc,\n",
    "    \"test_proc\": test_proc,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "for ax, (name, df) in zip(axes, datasets.items()):\n",
    "    counts = df[target_col].value_counts().sort_index()\n",
    "    ratios = counts / counts.sum()\n",
    "\n",
    "    ax.bar(ratios.index.astype(str), ratios.values, color=[\"tab:blue\", \"tab:red\"])\n",
    "    ax.set_xlabel(target_col)\n",
    "    ax.set_title(f\"Class Ratio in {name}\")\n",
    "\n",
    "    for i, v in enumerate(ratios.values):\n",
    "        ax.text(i, v + 0.01, f\"{v:.2%}\", ha=\"center\")\n",
    "\n",
    "axes[0].set_ylabel(\"Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff921610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "def snapshot(df, step, split, group_col, target_col, base_cols):\n",
    "    return {\n",
    "        \"step\": step,\n",
    "        \"split\": split,\n",
    "        \"rows\": len(df),\n",
    "        \"stays\": df[group_col].nunique(),\n",
    "        \"pos_rate\": df[target_col].mean(),\n",
    "        \"missing_rate\": df[base_cols].isna().mean().mean(),\n",
    "    }\n",
    "\n",
    "def plot_overview(summary_df, title=\"Preprocessing Overview\"):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 9))\n",
    "    sns.barplot(data=summary_df, x=\"step\", y=\"rows\", hue=\"split\", ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Rows by Step\")\n",
    "    axes[0, 0].set_ylabel(\"rows\")\n",
    "\n",
    "    sns.barplot(data=summary_df, x=\"step\", y=\"stays\", hue=\"split\", ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"Unique Stays by Step\")\n",
    "    axes[0, 1].set_ylabel(\"unique stays\")\n",
    "\n",
    "    sns.barplot(data=summary_df, x=\"step\", y=\"missing_rate\", hue=\"split\", ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Avg Missing Rate (base_cols)\")\n",
    "    axes[1, 0].set_ylabel(\"missing rate\")\n",
    "\n",
    "    sns.barplot(data=summary_df, x=\"step\", y=\"pos_rate\", hue=\"split\", ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Positive Rate\")\n",
    "    axes[1, 1].set_ylabel(\"pos rate\")\n",
    "\n",
    "    for ax in axes.ravel():\n",
    "        ax.tick_params(axis=\"x\", rotation=20)\n",
    "        ax.legend(loc=\"best\")\n",
    "    plt.suptitle(title, y=1.02, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_age_filter(train_before, train_after, test_before, test_after, age_col):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "    sns.histplot(train_before[age_col], bins=30, color=\"#999999\", label=\"before\", stat=\"density\", ax=axes[0])\n",
    "    sns.histplot(train_after[age_col], bins=30, color=\"#2ca02c\", label=\"after\", stat=\"density\", ax=axes[0])\n",
    "    axes[0].set_title(\"Train Age Distribution\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    sns.histplot(test_before[age_col], bins=30, color=\"#999999\", label=\"before\", stat=\"density\", ax=axes[1])\n",
    "    sns.histplot(test_after[age_col], bins=30, color=\"#1f77b4\", label=\"after\", stat=\"density\", ax=axes[1])\n",
    "    axes[1].set_title(\"Test Age Distribution\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_sampling_per_stay(before_df, after_df, group_col, title):\n",
    "    before_counts = before_df.groupby(group_col).size()\n",
    "    after_counts = after_df.groupby(group_col).size()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    sns.histplot(before_counts, bins=30, color=\"#999999\", ax=axes[0])\n",
    "    axes[0].set_title(f\"{title}: rows per stay (before)\")\n",
    "    axes[0].set_xlabel(\"rows per stay\")\n",
    "    axes[0].set_xlim(0, 1300)\n",
    "    sns.histplot(after_counts, bins=30, color=\"#ff7f0e\", ax=axes[1])\n",
    "    axes[1].set_title(f\"{title}: rows per stay (after)\")\n",
    "    axes[1].set_xlabel(\"rows per stay\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_missing_indicator(df, base_cols, title, top_n=12):\n",
    "    miss_cols = [f\"{c}_miss\" for c in base_cols if f\"{c}_miss\" in df.columns]\n",
    "    miss_rate = df[miss_cols].mean().sort_values(ascending=False).head(top_n)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=miss_rate.values, y=miss_rate.index, color=\"#9467bd\")\n",
    "    plt.title(f\"{title}: top missing indicators\")\n",
    "    plt.xlabel(\"mean missing (1=missing)\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_imputation_effect(before_df, after_df, base_cols, title):\n",
    "    before_rate = before_df[base_cols].isna().mean().mean()\n",
    "    after_rate = after_df[base_cols].isna().mean().mean()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(x=[\"before\", \"after\"], y=[before_rate, after_rate], color=\"#8c564b\")\n",
    "    plt.title(f\"{title}: missing rate before vs after impute\")\n",
    "    plt.ylabel(\"avg missing rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_balance(before_df, after_df, target_col, title):\n",
    "    before_counts = before_df[target_col].value_counts().sort_index()\n",
    "    after_counts = after_df[target_col].value_counts().sort_index()\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"class\": [\"0\", \"1\", \"0\", \"1\"],\n",
    "        \"count\": [before_counts.get(0, 0), before_counts.get(1, 0),\n",
    "                  after_counts.get(0, 0), after_counts.get(1, 0)],\n",
    "        \"stage\": [\"before\", \"before\", \"after\", \"after\"],\n",
    "    })\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.barplot(data=df_plot, x=\"class\", y=\"count\", hue=\"stage\")\n",
    "    plt.title(f\"{title}: class balance\")\n",
    "    plt.xlabel(target_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9967f",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== raw snapshot ======\n",
    "snapshots = []\n",
    "train_raw = train_df.copy()\n",
    "test_raw = test_df.copy()\n",
    "snapshots.append(snapshot(train_raw, \"raw\", \"train\", group_col, target_col, base_cols))\n",
    "snapshots.append(snapshot(test_raw, \"raw\", \"test\", group_col, target_col, base_cols))\n",
    "\n",
    "# ====== 나이 필터 적용 ======\n",
    "train_df, test_df = apply_age_filter(\n",
    "    train_df, test_df, age_col=\"feature1\", min_age=18, max_age=60, enabled=True\n",
    ")\n",
    "plot_age_filter(train_raw, train_df, test_raw, test_df, age_col=\"feature1\")\n",
    "snapshots.append(snapshot(train_df, \"age_filter\", \"train\", group_col, target_col, base_cols))\n",
    "snapshots.append(snapshot(test_df, \"age_filter\", \"test\", group_col, target_col, base_cols))\n",
    "\n",
    "# ====== stay별 10개 샘플 ======\n",
    "train_before_sample = train_df.copy()\n",
    "test_before_sample = test_df.copy()\n",
    "train_proc = sample_k_per_stay(train_df, group_col, time_col, k=10)\n",
    "test_proc = sample_k_per_stay(test_df, group_col, time_col, k=10)\n",
    "plot_sampling_per_stay(train_before_sample, train_proc, group_col, \"Train\")\n",
    "plot_sampling_per_stay(test_before_sample, test_proc, group_col, \"Test\")\n",
    "snapshots.append(snapshot(train_proc, \"sample_k\", \"train\", group_col, target_col, base_cols))\n",
    "snapshots.append(snapshot(test_proc, \"sample_k\", \"test\", group_col, target_col, base_cols))\n",
    "\n",
    "# ====== 파생변수 생성 ======\n",
    "# train_proc = add_missing_and_time_features(train_proc, base_cols)\n",
    "# test_proc = add_missing_and_time_features(test_proc, base_cols)\n",
    "# plot_missing_indicator(train_proc, base_cols, \"Train\")\n",
    "# plot_missing_indicator(test_proc, base_cols, \"Test\")\n",
    "# snapshots.append(snapshot(train_proc, \"add_missing\", \"train\", group_col, target_col, base_cols))\n",
    "# snapshots.append(snapshot(test_proc, \"add_missing\", \"test\", group_col, target_col, base_cols))\n",
    "\n",
    "# ====== 결측치 처리 ======\n",
    "train_before_impute = train_proc.copy()\n",
    "test_before_impute = test_proc.copy()\n",
    "train_medians = train_proc[base_cols].median()\n",
    "train_proc = impute_base(train_proc, base_cols, train_medians)\n",
    "test_proc = impute_base(test_proc, base_cols, train_medians)\n",
    "plot_imputation_effect(train_before_impute, train_proc, base_cols, \"Train\")\n",
    "plot_imputation_effect(test_before_impute, test_proc, base_cols, \"Test\")\n",
    "snapshots.append(snapshot(train_proc, \"impute\", \"train\", group_col, target_col, base_cols))\n",
    "snapshots.append(snapshot(test_proc, \"impute\", \"test\", group_col, target_col, base_cols))\n",
    "\n",
    "# ====== 클래스 비율 맞추기 ======\n",
    "train_before_balance = train_proc.copy()\n",
    "train_proc = balance_ratio(train_proc, target_col=target_col, ratio_pos=0.08)\n",
    "plot_class_balance(train_before_balance, train_proc, target_col, \"Train\")\n",
    "snapshots.append(snapshot(train_proc, \"balance\", \"train\", group_col, target_col, base_cols))\n",
    "\n",
    "# ====== 요약 테이블 + Overview Plot ======\n",
    "summary_df = pd.DataFrame(snapshots)\n",
    "display(summary_df)\n",
    "plot_overview(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11182a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sampling_per_stay(before_df, after_df, group_col, title):\n",
    "    before_counts = before_df.groupby(group_col).size()\n",
    "    after_counts = after_df.groupby(group_col).size()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    sns.histplot(before_counts, bins=30, color=\"#999999\", ax=axes[0])\n",
    "    axes[0].set_title(f\"{title}: rows per stay (before)\")\n",
    "    axes[0].set_xlabel(\"rows per stay\")\n",
    "    axes[0].set_xlim(0, 1100)\n",
    "    sns.histplot(after_counts, bins=30, color=\"#ff7f0e\", ax=axes[1])\n",
    "    axes[1].set_title(f\"{title}: rows per stay (after)\")\n",
    "    axes[1].set_xlabel(\"rows per stay\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "train_before_sample = train_df.copy()\n",
    "test_before_sample = test_df.copy()\n",
    "train_proc = sample_k_per_stay(train_df, group_col, time_col, k=10)\n",
    "test_proc = sample_k_per_stay(test_df, group_col, time_col, k=10)\n",
    "plot_sampling_per_stay(train_before_sample, train_proc, group_col, \"Train\")\n",
    "plot_sampling_per_stay(test_before_sample, test_proc, group_col, \"Test\")\n",
    "snapshots.append(snapshot(train_proc, \"sample_k\", \"train\", group_col, target_col, base_cols))\n",
    "snapshots.append(snapshot(test_proc, \"sample_k\", \"test\", group_col, target_col, base_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb12044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_data_loss(before_df, after_df, group_col, label=\"\"):\n",
    "    rows_before = len(before_df)\n",
    "    rows_after = len(after_df)\n",
    "    row_loss = rows_before - rows_after\n",
    "    row_loss_rate = row_loss / rows_before if rows_before else 0\n",
    "\n",
    "    stays_before = before_df[group_col].nunique()\n",
    "    stays_after = after_df[group_col].nunique()\n",
    "    stay_loss = stays_before - stays_after\n",
    "    stay_loss_rate = stay_loss / stays_before if stays_before else 0\n",
    "\n",
    "    print(f\"[{label}] rows: {rows_before} -> {rows_after} (loss {row_loss:,}, {row_loss_rate:.2%})\")\n",
    "    print(f\"[{label}] stays: {stays_before} -> {stays_after} (loss {stay_loss:,}, {stay_loss_rate:.2%})\")\n",
    "    return {\n",
    "        \"label\": label,\n",
    "        \"rows_before\": rows_before,\n",
    "        \"rows_after\": rows_after,\n",
    "        \"row_loss\": row_loss,\n",
    "        \"row_loss_rate\": row_loss_rate,\n",
    "        \"stays_before\": stays_before,\n",
    "        \"stays_after\": stays_after,\n",
    "        \"stay_loss\": stay_loss,\n",
    "        \"stay_loss_rate\": stay_loss_rate,\n",
    "    }\n",
    "\n",
    "def plot_data_loss(loss_dicts, title=\"Data Loss After Sampling\"):\n",
    "    df = pd.DataFrame(loss_dicts)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.barplot(data=df, x=\"label\", y=\"row_loss_rate\", ax=axes[0], color=\"#d62728\")\n",
    "    axes[0].set_title(\"Row Loss Rate\")\n",
    "    axes[0].set_ylabel(\"loss rate\")\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].tick_params(axis=\"x\", rotation=15)\n",
    "\n",
    "    sns.barplot(data=df, x=\"label\", y=\"stay_loss_rate\", ax=axes[1], color=\"#9467bd\")\n",
    "    axes[1].set_title(\"Stay Loss Rate\")\n",
    "    axes[1].set_ylabel(\"loss rate\")\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].tick_params(axis=\"x\", rotation=15)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 사용 예시 (sampling 전후)\n",
    "train_loss = calc_data_loss(train_before_sample, train_proc, group_col, label=\"Train sample_k\")\n",
    "test_loss = calc_data_loss(test_before_sample, test_proc, group_col, label=\"Test sample_k\")\n",
    "plot_data_loss([train_loss, test_loss], title=\"Sampling Data Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a02e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_col = \"died_in_icu\"\n",
    "\n",
    "datasets = {\n",
    "    \"train_proc\": train_proc,\n",
    "    \"test_proc\": test_proc,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "\n",
    "for ax, (name, df) in zip(axes, datasets.items()):\n",
    "    counts = df[target_col].value_counts().sort_index()\n",
    "    ratios = counts / counts.sum()\n",
    "\n",
    "    ax.bar(ratios.index.astype(str), ratios.values, color=[\"tab:blue\", \"tab:red\"])\n",
    "    ax.set_xlabel(target_col)\n",
    "    ax.set_title(f\"Class Ratio in {name}\")\n",
    "\n",
    "    for i, v in enumerate(ratios.values):\n",
    "        ax.text(i, v + 0.01, f\"{v:.2%}\", ha=\"center\")\n",
    "\n",
    "axes[0].set_ylabel(\"Ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def age_group_stats(df, age_col=\"age\", group_col=\"patientunitstayid\", time_col=\"observationoffset\"):\n",
    "    # 나이 구간 정의(필요하면 수정)\n",
    "    bins = [0, 18, 30, 40, 50, 60, 70, 80, 200]\n",
    "    labels = [\"0-17\",\"18-29\",\"30-39\",\"40-49\",\"50-59\",\"60-69\",\"70-79\",\"80+\"]\n",
    "\n",
    "    g = df.copy()\n",
    "    g[\"age_group\"] = pd.cut(g[age_col], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    # 그룹별 환자 수(중복 제거)\n",
    "    stay_counts = g.groupby(\"age_group\")[group_col].nunique()\n",
    "\n",
    "    # 그룹별 타임시리즈(offset) 개수: 행 수\n",
    "    offset_counts = g.groupby(\"age_group\").size()\n",
    "\n",
    "    # 출력\n",
    "    print(\"== Age group -> unique stays ==\")\n",
    "    print(stay_counts)\n",
    "    print(\"\\n== Age group -> total offsets(rows) ==\")\n",
    "    print(offset_counts)\n",
    "\n",
    "    # 시각화\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=False)\n",
    "    stay_counts.plot(kind=\"bar\", ax=axes[0], color=\"tab:blue\", title=\"Unique stays by age group\")\n",
    "    axes[0].set_ylabel(\"Count\")\n",
    "    axes[0].set_xlabel(\"Age group\")\n",
    "\n",
    "    offset_counts.plot(kind=\"bar\", ax=axes[1], color=\"tab:orange\", title=\"Offsets(rows) by age group\")\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "    axes[1].set_xlabel(\"Age group\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 사용 예시\n",
    "age_group_stats(train_df, age_col=\"feature1\", group_col=group_col, time_col=time_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feature_cols))\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e6a5b",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe614609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE로 불균형 처리 (train만)\n",
    "# 필요: pip install imbalanced-learn (또는 uv add imbalanced-learn)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 학습 데이터만 SMOTE 적용\n",
    "# smote = SMOTE(sampling_strategy=0.5 / 0.5, random_state=42, k_neighbors=5)\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "# X_test, y_test = smote.fit_resample(X_test, y_test) \n",
    "print(\"before:\", y_train.value_counts(normalize=True))\n",
    "print(\"after :\", pd.Series(y_train).value_counts(normalize=True))\n",
    "\n",
    "# 이후 모델 학습에 X_train_sm, y_train_sm 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc04b7",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbfe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "models = {}\n",
    "# 고정값으로 98:2 가정\n",
    "scale_pos_weight = 92/8\n",
    "\n",
    "models[\"XGBoost\"] = xgb.XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")\n",
    "\n",
    "\n",
    "def aggregate_patient_scores(df: pd.DataFrame, scores: np.ndarray):\n",
    "    tmp = df[[group_col, target_col]].copy()\n",
    "    tmp[\"score\"] = scores\n",
    "    y_patient = tmp.groupby(group_col)[target_col].max()\n",
    "    s_patient = tmp.groupby(group_col)[\"score\"].mean()\n",
    "    return y_patient, s_patient\n",
    "\n",
    "pred_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        scores = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        raw = model.decision_function(X_test)\n",
    "        scores = 1 / (1 + np.exp(-raw))\n",
    "\n",
    "    pred_scores[name] = scores\n",
    "\n",
    "print(\"models used:\", list(pred_scores.keys()))\n",
    "print(\"test n:\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화: ROC + Calibration + Decision Curve (SMOTE test 기준, row-level)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1) ROC\n",
    "ax = axes[0]\n",
    "for name, scores in pred_scores.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "    auc = roc_auc_score(y_test, scores)\n",
    "    ax.plot(fpr, tpr, label=f\"{name} (AUC={auc:.3f})\")\n",
    "ax.plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "ax.set_xlabel(\"1 - Specificity\")\n",
    "ax.set_ylabel(\"Sensitivity\")\n",
    "ax.set_title(\"ROC Curves (SMOTE test)\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# 2) Calibration\n",
    "ax = axes[1]\n",
    "for name, scores in pred_scores.items():\n",
    "    prob_true, prob_pred = calibration_curve(y_test, scores, n_bins=10, strategy=\"uniform\")\n",
    "    ax.plot(prob_pred, prob_true, marker=\"o\", label=name)\n",
    "ax.plot([0, 1], [0, 1], \"k--\", alpha=0.5, label=\"Ideal\")\n",
    "ax.set_xlabel(\"Mean predicted probability\")\n",
    "ax.set_ylabel(\"Fraction of positives\")\n",
    "ax.set_title(\"Calibration Curves (SMOTE test)\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "# 3) Decision Curve\n",
    "ax = axes[2]\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "def decision_curve(y_true, scores):\n",
    "    n = len(y_true)\n",
    "    net_benefit = []\n",
    "    for t in thresholds:\n",
    "        preds = scores >= t\n",
    "        tp = ((preds == 1) & (y_true == 1)).sum()\n",
    "        fp = ((preds == 1) & (y_true == 0)).sum()\n",
    "        nb = (tp / n) - (fp / n) * (t / (1 - t))\n",
    "        net_benefit.append(nb)\n",
    "    return np.array(net_benefit)\n",
    "\n",
    "for name, scores in pred_scores.items():\n",
    "    nb = decision_curve(np.array(y_test), scores)\n",
    "    ax.plot(thresholds, nb, label=name)\n",
    "\n",
    "prevalence = np.mean(y_test)\n",
    "nb_all = prevalence - (1 - prevalence) * (thresholds / (1 - thresholds))\n",
    "ax.plot(thresholds, nb_all, \"k--\", alpha=0.4, label=\"Treat all\")\n",
    "ax.plot(thresholds, np.zeros_like(thresholds), \"k:\", alpha=0.6, label=\"Treat none\")\n",
    "\n",
    "ax.set_xlabel(\"Threshold probability\")\n",
    "ax.set_ylabel(\"Net benefit\")\n",
    "ax.set_title(\"Decision Curve Analysis (SMOTE test)\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 서브플롯 (환자 단위 집계 기준)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "n_models = len(pred_scores)\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(n_models / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(5 * n_cols, 4 * n_rows))\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for ax, (name, scores) in zip(axes, pred_scores.items()):\n",
    "    y_pred = (scores >= 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=ax, cmap=\"Blues\", colorbar=False)\n",
    "    ax.set_title(f\"{name}\")\n",
    "\n",
    "for ax in axes[n_models:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d26fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "\n",
    "def evaluate_row_level(\n",
    "    pred_scores: dict[str, np.ndarray | pd.Series],\n",
    "    y_true: np.ndarray | pd.Series,\n",
    "    threshold: float = 0.5,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    row-level 성능 평가 (SMOTE test 기준)\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true).astype(int)\n",
    "\n",
    "    results = []\n",
    "    for name, scores in pred_scores.items():\n",
    "        y_score = np.asarray(scores).astype(float)\n",
    "        y_pred = (y_score >= threshold).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        if np.unique(y_true).size < 2:\n",
    "            auc = np.nan\n",
    "            ap = np.nan\n",
    "        else:\n",
    "            auc = roc_auc_score(y_true, y_score)\n",
    "            ap = average_precision_score(y_true, y_score)\n",
    "\n",
    "        results.append({\n",
    "            \"model\": name,\n",
    "            \"N_rows\": len(y_true),\n",
    "            \"pos_rate\": float(y_true.mean()),\n",
    "            \"threshold\": threshold,\n",
    "            \"ACC\": acc,\n",
    "            \"PREC\": prec,\n",
    "            \"REC\": rec,\n",
    "            \"F1\": f1,\n",
    "            \"AUC\": auc,\n",
    "            \"PR-AUC\": ap,\n",
    "        })\n",
    "\n",
    "    out = (\n",
    "        pd.DataFrame(results)\n",
    "        .set_index(\"model\")\n",
    "        .sort_values([\"PR-AUC\", \"AUC\"], ascending=False)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# 실행 (SMOTE test 기준)\n",
    "metrics_df = evaluate_row_level(\n",
    "    pred_scores=pred_scores,\n",
    "    y_true=y_test,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "print(metrics_df.to_string(float_format=lambda x: f\"{x:.4f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 분석 + 중요 피처 Top-N (row-level, 현재 models 기준)\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_shap = X_test.sample(n=min(1000, len(X_test)), random_state=42)\n",
    "top_n = len(feature_cols)\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        if name in [\"RF\", \"XGBoost\", \"LightGBM\", \"CatBoost\"]:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X_shap)\n",
    "        else:\n",
    "            bg = X_shap.sample(100, random_state=42)\n",
    "            explainer = shap.KernelExplainer(model.predict_proba, bg)\n",
    "            shap_values = explainer.shap_values(X_shap, nsamples=100)\n",
    "\n",
    "        if isinstance(shap_values, list) and len(shap_values) > 1:\n",
    "            sv = shap_values[1]\n",
    "        else:\n",
    "            sv = shap_values\n",
    "\n",
    "        mean_abs = np.abs(sv).mean(axis=0)\n",
    "        imp = pd.Series(mean_abs, index=X_shap.columns).sort_values(ascending=False)\n",
    "\n",
    "        print(f\"\\n{name} Top {top_n} features:\")\n",
    "        print(imp.head(top_n))\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        imp.head(top_n).sort_values().plot(kind=\"barh\")\n",
    "        plt.title(f\"{name} SHAP Feature Importance (Top {top_n})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        shap.summary_plot(sv, X_shap, show=True, plot_type=\"bar\")\n",
    "        shap.summary_plot(sv, X_shap, show=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP failed for {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cols = feature_cols\n",
    "# 상관관계 계산\n",
    "corr = X_train[cols].corr(method=\"pearson\")\n",
    "display(corr)\n",
    "\n",
    "# 히트맵 시각화\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation (Selected Features)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols 기반 사망/생존별 결측률\n",
    "target_col = \"died_in_icu\"\n",
    "\n",
    "missing_rate_by_t = (\n",
    "    train_df[feature_cols]\n",
    "    .isna()\n",
    "    .groupby(train_df[target_col])\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# 보기 좋게 전치 (feature 행, target 컬럼)\n",
    "missing_rate_by_t_T = missing_rate_by_t.T\n",
    "missing_rate_by_t_T.columns = [f\"{target_col}={c}\" for c in missing_rate_by_t_T.columns]\n",
    "\n",
    "display(missing_rate_by_t_T)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
